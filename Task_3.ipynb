{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ed620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Employee Performance Bonus Eligibility\n",
    "\n",
    "team_data = {\n",
    "    \"Ravi\": 92,\n",
    "    \"Anita\": 88,\n",
    "    \"Kiran\": 92,\n",
    "    \"Suresh\": 85\n",
    "}\n",
    "\n",
    "highest_score = max(team_data.values())\n",
    "eligible_members = [emp for emp, marks in team_data.items() if marks == highest_score]\n",
    "\n",
    "print(f\"Top Performers Eligible for Bonus: {', '.join(eligible_members)} (Score: {highest_score})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Search Query Keyword Analysis\n",
    "\n",
    "import string\n",
    "\n",
    "input_text = \"Buy mobile phone buy phone online\"\n",
    "formatted_text = input_text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "word_list = formatted_text.split()\n",
    "\n",
    "word_count_map = {}\n",
    "\n",
    "for item in word_list:\n",
    "    word_count_map[item] = word_count_map.get(item, 0) + 1\n",
    "\n",
    "duplicate_words = {word: count for word, count in word_count_map.items() if count > 1}\n",
    "\n",
    "print(duplicate_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3: Sensor Data Validation\n",
    "\n",
    "sensor_readings = [3, 4, 7, 8, 10, 12, 5]\n",
    "even_readings = []\n",
    "\n",
    "for index, value in enumerate(sensor_readings):\n",
    "    if value % 2 == 0:\n",
    "        even_readings.append((index, value))\n",
    "\n",
    "print(\"Valid Sensor Readings (Hour, Value):\")\n",
    "print(even_readings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f31692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4: Email Domain Usage Analysis\n",
    "\n",
    "email_list = [\n",
    "    \"ravi@gmail.com\",\n",
    "    \"anita@yahoo.com\",\n",
    "    \"kiran@gmail.com\",\n",
    "    \"suresh@gmail.com\",\n",
    "    \"meena@yahoo.com\"\n",
    "]\n",
    "\n",
    "domain_count = {}\n",
    "\n",
    "for mail in email_list:\n",
    "    domain_name = mail.split(\"@\")[-1]\n",
    "    domain_count[domain_name] = domain_count.get(domain_name, 0) + 1\n",
    "\n",
    "total_emails = len(email_list)\n",
    "\n",
    "for domain, count in domain_count.items():\n",
    "    percentage = (count / total_emails) * 100\n",
    "    print(f\"{domain}: {percentage:.0f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5: Sales Spike Detection\n",
    "\n",
    "daily_sales = [1200, 1500, 900, 2200, 1400, 3000]\n",
    "\n",
    "average_sales = sum(daily_sales) / len(daily_sales)\n",
    "threshold_value = average_sales * 1.3\n",
    "\n",
    "for day_index, sale_amount in enumerate(daily_sales, 1):\n",
    "    if sale_amount > threshold_value:\n",
    "        print(f\"Day {day_index}: {sale_amount}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75110323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6: Duplicate User ID Detection\n",
    "\n",
    "user_ids = [\"user1\", \"user2\", \"user1\", \"user3\", \"user1\", \"user3\"]\n",
    "\n",
    "id_count_map = {}\n",
    "\n",
    "for user in user_ids:\n",
    "    id_count_map[user] = id_count_map.get(user, 0) + 1\n",
    "\n",
    "for user, frequency in id_count_map.items():\n",
    "    if frequency > 1:\n",
    "        print(f\"{user} â†’ {frequency} times\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
